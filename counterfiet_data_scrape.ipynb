{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddb5d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from selenium import webdriver\\nfrom bs4 import BeautifulSoup\\nimport time\\nimport requests\\nfrom selenium.webdriver.common.keys import Keys\\nfrom selenium.webdriver.common.by import By\\nfrom selenium.webdriver.support.ui import WebDriverWait\\nfrom selenium.webdriver.support import expected_conditions as EC\\nfrom selenium.common.exceptions import NoSuchElementException\\nimport csv\\nimport pandas as pd\\n\\n#  Any infinity scroll URL\\nmainURL = \"https://dir.indiamart.com/\"\\nvar = \"adidas shoes\"\\n\\n# url = \"https://in.pinterest.com/search/pins/?q=\" + var \\n\\nurl = \"https://dir.indiamart.com/search.mp?ss=shoes+nike&mcatid=569&catid=145&prdsrc=1&stype=attr=1|attrS&res=RC2\" \\n#url=\"https://dir.indiamart.com/search.mp?ss=nike+shoes&mcatid=184123&catid=714&prdsrc=1&stype=attr=1|attrS&res=RC3\"\\nprint(\"URL\",url);\\n\\nsleepTimer = 3    # Waiting 1 second for page to load\\nimage_limits = 6000\\nimages_per_page = []\\nno_of_images = []\\n\\nimages = []\\ntitle = []\\nprice = []\\nbrand = []\\nreview_count = []\\n\\n#  Bluetooth bug circumnavigate\\noptions = webdriver.ChromeOptions() \\noptions.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\\n\\ndriver = webdriver.Chrome(\"C:/Program Files (x86)/chromedriver.exe\", options=options)  # path=r\\'to/chromedriver.exe\\'\\ndriver.get(url)\\n\\n\\n\\n\\ncsv_data = []\\n\\ndef scroolWindow(): \\n    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\");\\n    time.sleep(sleepTimer)\\n    scrapedata()\\n    \\ndef scrapedata():\\n\\n    soup = BeautifulSoup(driver.page_source,\\'html.parser\\')\\n    for (i, divDom) in enumerate(soup.find_all(\\'div\\', {\\'class\\': \\'prd-top df flx100 oh\\'})):\\n\\n        if divDom.find(\\'a\\', {\\'class\\' : \\'prd-name\\'}) and divDom.find(\\'div\\',{\\'class\\':\\'prd-list-prc flx100 tac grdprctyp\\'}) and divDom.find(\\'h4\\',{\\'class\\':\\'fwn fs11 tac clr7 flx100 naIsq\\'}): #and divDom.find(\\'span\\',{\\'class\\':\\'a-size-base\\'}) and divDom.find(\\'h5\\', {\\'class\\': \\'s-line-clamp-1\\'}) and not divDom.find(\\'div\\', {\\'class\\': \\'sbv-product-container\\'}):\\n            if divDom.find(\\'a\\', {\\'class\\' : \\'prd-name\\'}).text not in title:\\n                title.append(divDom.find(\\'a\\', {\\'class\\' : \\'prd-name\\'}).text)\\n                price.append(divDom.find(\\'div\\',{\\'class\\':\\'prd-list-prc flx100 tac grdprctyp\\'}).text)\\n                brand.append(divDom.find(\\'h4\\', {\\'class\\': \\'fwn fs11 tac clr7 flx100 naIsq\\'}).text)\\n                #review_count.append(divDom.find(\\'span\\', {\\'class\\': \\'a-size-base s-underline-text\\'}).text)\\n    print(title )\\n    print(price)\\n    print(brand)\\n    if len(price) < image_limits:\\n        try:\\n            print(\"loading\")\\n            next_button = driver.find_element(By.XPATH, \"//div[@class=\\'prd-shmr flx100 tac mt10 mb10\\']\")\\n            next_button.click()\\n            credentials={\\n                \"uname\":\"sandrasanu26@gmail.com\",\\n                \"password\":\"scraping123\"\\n            }\\n\\n            s=requests.session()\\n            response =s.post(url,data=credentials)\\n            print(response.status_code)\\n            print(\"clicked\")\\n            scroolWindow()\\n        except NoSuchElementException:\\n            # Handle the exception\\n            # Save the scraped data to a CSV file\\n            print(\"IN NoSuchElementException\")\\n            \\n        finally:\\n            # Quit the webdriver instance\\n            print(\"IN FINALLY\")\\n            with open(\\'stockx scraped \\'+var+\\' data.csv\\', \\'w\\', newline=\\'\\') as file:\\n                writer = csv.writer(file)\\n                data=pd.DataFrame()\\n                data[\"Company\"]=pd.Series(brand)\\n                data[\"Title\"]=pd.Series(title)\\n                data[\"Price\"]=pd.Series(price)\\n                #data[\"Rating\"]=pd.Series(rating)\\n                #data[\"review_count\"]=pd.Series(review_count)\\n\\n                #data[\"Image\"]=pd.Series(Image)\\n                gfg_csv_data = data.to_csv(\\'indiamart_meta6.csv\\', index = True)\\n                print(\\'\\nCSV String:\\n\\', gfg_csv_data)\\n            driver.quit()\\n\\nscrapedata()'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#  Any infinity scroll URL\n",
    "mainURL = \"https://dir.indiamart.com/\"\n",
    "var = \"adidas shoes\"\n",
    "\n",
    "# url = \"https://in.pinterest.com/search/pins/?q=\" + var \n",
    "\n",
    "url = \"https://dir.indiamart.com/search.mp?ss=shoes+nike&mcatid=569&catid=145&prdsrc=1&stype=attr=1|attrS&res=RC2\" \n",
    "#url=\"https://dir.indiamart.com/search.mp?ss=nike+shoes&mcatid=184123&catid=714&prdsrc=1&stype=attr=1|attrS&res=RC3\"\n",
    "print(\"URL\",url);\n",
    "\n",
    "sleepTimer = 3    # Waiting 1 second for page to load\n",
    "image_limits = 6000\n",
    "images_per_page = []\n",
    "no_of_images = []\n",
    "\n",
    "images = []\n",
    "title = []\n",
    "price = []\n",
    "brand = []\n",
    "review_count = []\n",
    "\n",
    "#  Bluetooth bug circumnavigate\n",
    "options = webdriver.ChromeOptions() \n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "driver = webdriver.Chrome(\"C:/Program Files (x86)/chromedriver.exe\", options=options)  # path=r'to/chromedriver.exe'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "csv_data = []\n",
    "\n",
    "def scroolWindow(): \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\");\n",
    "    time.sleep(sleepTimer)\n",
    "    scrapedata()\n",
    "    \n",
    "def scrapedata():\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    for (i, divDom) in enumerate(soup.find_all('div', {'class': 'prd-top df flx100 oh'})):\n",
    "\n",
    "        if divDom.find('a', {'class' : 'prd-name'}) and divDom.find('div',{'class':'prd-list-prc flx100 tac grdprctyp'}) and divDom.find('h4',{'class':'fwn fs11 tac clr7 flx100 naIsq'}): #and divDom.find('span',{'class':'a-size-base'}) and divDom.find('h5', {'class': 's-line-clamp-1'}) and not divDom.find('div', {'class': 'sbv-product-container'}):\n",
    "            if divDom.find('a', {'class' : 'prd-name'}).text not in title:\n",
    "                title.append(divDom.find('a', {'class' : 'prd-name'}).text)\n",
    "                price.append(divDom.find('div',{'class':'prd-list-prc flx100 tac grdprctyp'}).text)\n",
    "                brand.append(divDom.find('h4', {'class': 'fwn fs11 tac clr7 flx100 naIsq'}).text)\n",
    "                #review_count.append(divDom.find('span', {'class': 'a-size-base s-underline-text'}).text)\n",
    "    print(title )\n",
    "    print(price)\n",
    "    print(brand)\n",
    "    if len(price) < image_limits:\n",
    "        try:\n",
    "            print(\"loading\")\n",
    "            next_button = driver.find_element(By.XPATH, \"//div[@class='prd-shmr flx100 tac mt10 mb10']\")\n",
    "            next_button.click()\n",
    "            credentials={\n",
    "                \"uname\":\"sandrasanu26@gmail.com\",\n",
    "                \"password\":\"scraping123\"\n",
    "            }\n",
    "\n",
    "            s=requests.session()\n",
    "            response =s.post(url,data=credentials)\n",
    "            print(response.status_code)\n",
    "            print(\"clicked\")\n",
    "            scroolWindow()\n",
    "        except NoSuchElementException:\n",
    "            # Handle the exception\n",
    "            # Save the scraped data to a CSV file\n",
    "            print(\"IN NoSuchElementException\")\n",
    "            \n",
    "        finally:\n",
    "            # Quit the webdriver instance\n",
    "            print(\"IN FINALLY\")\n",
    "            with open('stockx scraped '+var+' data.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                data=pd.DataFrame()\n",
    "                data[\"Company\"]=pd.Series(brand)\n",
    "                data[\"Title\"]=pd.Series(title)\n",
    "                data[\"Price\"]=pd.Series(price)\n",
    "                #data[\"Rating\"]=pd.Series(rating)\n",
    "                #data[\"review_count\"]=pd.Series(review_count)\n",
    "\n",
    "                #data[\"Image\"]=pd.Series(Image)\n",
    "                gfg_csv_data = data.to_csv('indiamart_meta6.csv', index = True)\n",
    "                print('\\nCSV String:\\n', gfg_csv_data)\n",
    "            driver.quit()\n",
    "\n",
    "scrapedata()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a901c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#  Any infinity scroll URL\n",
    "mainURL = \"https://dir.indiamart.com/\"\n",
    "var = \"adidas shoes\"\n",
    "# initialize the web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# navigate to the website\n",
    "driver.get(\"https://stockx.com/search?s=puma+shoes\")\n",
    "#if driver.find_element(By.XPATH,\"//div[@class='banner-close-btn-container']\"):\n",
    "    # wait for the accept cookies button to appear\n",
    "def accept_cookies():\n",
    "    accept_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept All')]\"))\n",
    "    )\n",
    "\n",
    "    # click the accept button\n",
    "    accept_button.click()\n",
    "    scrapedata()\n",
    "\n",
    "\n",
    "    # continue with your web scraping code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleepTimer = 3    # Waiting 1 second for page to load\n",
    "image_limits = 6000\n",
    "images_per_page = []\n",
    "no_of_images = []\n",
    "\n",
    "images = []\n",
    "title = []\n",
    "price = []\n",
    "brand = []\n",
    "review_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b018527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "next page.......................................................\n",
      "IN NoSuchElementException\n",
      "IN FINALLY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26548\\871662549.py:44: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  data[\"Title\"]=pd.Series(title)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26548\\871662549.py:45: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  data[\"Price\"]=pd.Series(price)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'stockxdata_puma.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCSV String:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, metadata_csv_data)\n\u001b[0;32m     52\u001b[0m             driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[1;32m---> 54\u001b[0m \u001b[43mscrapedata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mscrapedata\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries(price)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#data[\"Rating\"]=pd.Series(rating)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m#data[\"review_count\"]=pd.Series(review_count)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m#data[\"Image\"]=pd.Series(Image)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     metadata_csv_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstockxdata_puma.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCSV String:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, metadata_csv_data)\n\u001b[0;32m     52\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'stockxdata_puma.csv'"
     ]
    }
   ],
   "source": [
    "csv_data = []\n",
    "\n",
    "def scroolWindow(): \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\");\n",
    "    time.sleep(sleepTimer)\n",
    "    scrapedata()\n",
    "    \n",
    "def scrapedata():\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    for (i, divDom) in enumerate(soup.find_all('div', {'class': 'css-111hzm2-GridProductTileContainer'})):\n",
    "\n",
    "        if divDom.find('div', {'class' : 'css-0'}) and divDom.find('div',{'class':'css-1i6xaee'}): #and divDom.find('h4',{'class':'fwn fs11 tac clr7 flx100 naIsq'}): #and divDom.find('span',{'class':'a-size-base'}) and divDom.find('h5', {'class': 's-line-clamp-1'}) and not divDom.find('div', {'class': 'sbv-product-container'}):\n",
    "            if divDom.find('div', {'class' : 'css-0'}).text not in title:\n",
    "                title.append(divDom.find('div', {'class' : 'css-0'}).text)\n",
    "                price.append(divDom.find('div',{'class':'css-1i6xaee'}).text)\n",
    "                #brand.append(divDom.find('h4', {'class': 'fwn fs11 tac clr7 flx100 naIsq'}).text)\n",
    "                #review_count.append(divDom.find('span', {'class': 'a-size-base s-underline-text'}).text)\n",
    "    print(title )\n",
    "    print(price)\n",
    "    #print(brand)\n",
    "    if len(price) < image_limits:\n",
    "        try:\n",
    "            print(\"next page.......................................................\")\n",
    "\n",
    "            next_button = driver.find_element(By.XPATH, \"//a[@aria-label='Next']\")\n",
    "            next_button.click()\n",
    "            #accept_cookies()\n",
    "\n",
    "            #print(\"next page.......................................................\")\n",
    "            scroolWindow()\n",
    "        except NoSuchElementException:\n",
    "            # Handle the exception\n",
    "            # Save the scraped data to a CSV file\n",
    "            print(\"IN NoSuchElementException\")\n",
    "            \n",
    "        finally:\n",
    "            # Quit the webdriver instance\n",
    "            print(\"IN FINALLY\")\n",
    "            with open('stockx scraped '+var+' data.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                data=pd.DataFrame()\n",
    "                #data[\"Company\"]=pd.Series(brand)\n",
    "                data[\"Title\"]=pd.Series(title)\n",
    "                data[\"Price\"]=pd.Series(price)\n",
    "                #data[\"Rating\"]=pd.Series(rating)\n",
    "                #data[\"review_count\"]=pd.Series(review_count)\n",
    "\n",
    "                #data[\"Image\"]=pd.Series(Image)\n",
    "                metadata_csv_data = data.to_csv('stockxdata_puma.csv', index = True)\n",
    "                print('\\nCSV String:\\n', metadata_csv_data)\n",
    "            driver.quit()\n",
    "\n",
    "scrapedata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c5d785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98e418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
